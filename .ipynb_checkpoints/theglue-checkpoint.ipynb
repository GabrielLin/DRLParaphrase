{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: \n",
    "- A corpus of paraphrase pairs {(X, Y )}\n",
    "- A corpus of non-paraphrase pairs {(X, Y−)} \n",
    "\n",
    "--> Task: Must separate these two from the original input data\n",
    "- A corpus of (non-parallel) sentences {X}. (Is this just... all sentences?) \n",
    "\n",
    "Output:\n",
    "- Generator G'\n",
    "_____\n",
    "1. Train the evaluator Mφ with {(X, Y)} and {(X, Y−)};\n",
    "2. Pre-train the generator Gθ with {(X, Y)};\n",
    "3. Init Gθ' := Gθ;\n",
    "4. while not converge do:\n",
    "    1. Sample a sentence X = [x1, . . . , xS] from the paraphrase corpus or the non-parallel corpus;\n",
    "    2. Generate a sentence Yˆ = [ˆy1, . . . , yˆT ] according to G_θ' given input X;\n",
    "    3. Set the gradient g_θ' = 0;\n",
    "    4. for t = 1 to T do:\n",
    "        1. Run N Monte Carlo simulations:\n",
    "        2. Compute the value function Q_t, rescale the reward to Q_t\n",
    "        3. Accumulate θ'-gradient\n",
    "    end\n",
    "    5. Update G_θ' using g_θ' with learning rate Y_G\n",
    "5. end\n",
    "6. return G_θ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES\n",
    "\n",
    "### Evaluator\n",
    "- Fix train.py to take in the data we want - no need to read_corpus, we just need to have pairs of (sent1, sent2, label)\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
